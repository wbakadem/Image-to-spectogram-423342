<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image to Spectrogram Audio</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: #1a1a1a;
            color: #eee;
            display: flex;
            flex-direction: column;
            align-items: center;
            padding: 20px;
        }
        .container {
            background: #2d2d2d;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.5);
            max-width: 800px;
            width: 100%;
            text-align: center;
        }
        canvas {
            max-width: 100%;
            height: auto;
            border: 1px solid #444;
            margin-top: 10px;
            background: #000;
        }
        .controls {
            margin: 20px 0;
            display: flex;
            gap: 10px;
            justify-content: center;
            flex-wrap: wrap;
        }
        button, input[type="file"] {
            padding: 10px 15px;
            cursor: pointer;
            border-radius: 4px;
            border: none;
            font-size: 14px;
        }
        button {
            background: #007bff;
            color: white;
            font-weight: bold;
        }
        button:disabled {
            background: #555;
            cursor: not-allowed;
        }
        input[type="file"] {
            background: #444;
            color: white;
        }
        #status {
            margin-top: 10px;
            color: #aaa;
            font-size: 0.9em;
            height: 20px;
        }
        audio {
            width: 100%;
            margin-top: 20px;
        }
        .settings {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin-bottom: 10px;
            font-size: 0.9em;
        }
        label { color: #ccc; }
    </style>
</head>
<body>

<div class="container">
    <h1>Картинка в Спектрограмму (Звук)</h1>
    <p>Загрузите изображение, чтобы превратить его в звук. <br>Ось Y = Частота, Ось X = Время, Яркость = Громкость.</p>

    <div class="settings">
        <div>
            <label>Длительность (сек):</label>
            <input type="number" id="durationInput" value="5" min="1" max="30" style="width: 50px;">
        </div>
        <div>
            <label>Макс. Частота (Hz):</label>
            <input type="number" id="freqInput" value="20000" step="1000" style="width: 70px;">
        </div>
    </div>

    <div class="controls">
        <input type="file" id="imageInput" accept="image/*">
        <button id="generateBtn" disabled>Сгенерировать Звук</button>
    </div>

    <div id="status">Ожидание загрузки изображения...</div>
    
    <canvas id="previewCanvas"></canvas>
    
    <audio id="audioPlayer" controls></audio>
</div>

<script>
    const imageInput = document.getElementById('imageInput');
    const generateBtn = document.getElementById('generateBtn');
    const canvas = document.getElementById('previewCanvas');
    const ctx = canvas.getContext('2d');
    const statusDiv = document.getElementById('status');
    const audioPlayer = document.getElementById('audioPlayer');
    const durationInput = document.getElementById('durationInput');
    const freqInput = document.getElementById('freqInput');

    let sourceImage = null;

    // 1. Загрузка изображения
    imageInput.addEventListener('change', (e) => {
        const file = e.target.files[0];
        if (!file) return;

        const reader = new FileReader();
        reader.onload = (event) => {
            const img = new Image();
            img.onload = () => {
                sourceImage = img;
                // Рисуем превью. Ограничиваем высоту для скорости обработки.
                // Для звука высота картинки = количество осцилляторов.
                // 200-300 пикселей достаточно для хорошего качества.
                const MAX_HEIGHT = 256; 
                let w = img.width;
                let h = img.height;
                
                // Масштабируем, сохраняя пропорции, но фиксируем высоту для производительности
                const scale = MAX_HEIGHT / h;
                canvas.height = MAX_HEIGHT;
                canvas.width = w * scale;

                ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
                
                generateBtn.disabled = false;
                statusDiv.innerText = `Изображение загружено. Разрешение для аудио: ${canvas.width}x${canvas.height}`;
            };
            img.src = event.target.result;
        };
        reader.readAsDataURL(file);
    });

    // 2. Генерация аудио
    generateBtn.addEventListener('click', async () => {
        if (!sourceImage) return;

        statusDiv.innerText = "Генерация... Пожалуйста, подождите (это может занять время)";
        generateBtn.disabled = true;
        
        // Даем UI обновиться перед тяжелым вычислением
        setTimeout(() => {
            processImageToAudio();
        }, 100);
    });

    function processImageToAudio() {
        try {
            const width = canvas.width;
            const height = canvas.height;
            const imageData = ctx.getImageData(0, 0, width, height).data;

            // Настройки аудио
            const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
            const sampleRate = audioCtx.sampleRate; // Обычно 44100 или 48000
            const duration = parseFloat(durationInput.value) || 5.0;
            const maxFreq = parseFloat(freqInput.value) || 20000;
            const minFreq = 50; // Минимальная частота

            const totalSamples = Math.floor(sampleRate * duration);
            const audioBuffer = audioCtx.createBuffer(1, totalSamples, sampleRate);
            const channelData = audioBuffer.getChannelData(0);

            // Фазы для каждого "осциллятора" (каждой строки пикселей)
            const phases = new Float32Array(height);
            
            // Таблица частот для каждой строки Y.
            // Y=0 (верх) - высокие частоты, Y=height (низ) - низкие частоты
            const freqs = new Float32Array(height);
            for (let y = 0; y < height; y++) {
                // Линейное распределение частот (можно сделать логарифмическое для музыкальности)
                // Инвертируем y, так как 0 это верх canvas
                const normalizedY = (height - 1 - y) / height; 
                freqs[y] = minFreq + (normalizedY * (maxFreq - minFreq));
            }

            // --- ГЛАВНЫЙ ЦИКЛ СИНТЕЗА ---
            // Проходим по каждому сэмплу аудио (времени)
            for (let i = 0; i < totalSamples; i++) {
                
                // Находим соответствующую позицию X на изображении
                const timePercent = i / totalSamples;
                const x = Math.floor(timePercent * width);
                
                let sampleValue = 0;

                // Проходим по вертикали (частотам) для текущего момента времени
                for (let y = 0; y < height; y++) {
                    // Индекс пикселя в массиве imageData (RGBA)
                    const pixelIndex = (y * width + x) * 4;
                    
                    // Вычисляем яркость пикселя (R+G+B)/3
                    const r = imageData[pixelIndex];
                    const g = imageData[pixelIndex + 1];
                    const b = imageData[pixelIndex + 2];
                    const brightness = (r + g + b) / 3.0 / 255.0;

                    // Оптимизация: если пиксель черный, пропускаем вычисления
                    if (brightness > 0.01) {
                        // Math.sin(фаза) * громкость
                        sampleValue += Math.sin(phases[y]) * brightness;
                    }

                    // Обновляем фазу для следующего сэмпла
                    // phase += 2 * PI * freq / sampleRate
                    phases[y] += (2 * Math.PI * freqs[y]) / sampleRate;
                    
                    // Сбрасываем фазу, чтобы число не стало бесконечно большим (хотя Math.sin справляется, но для чистоты)
                    if (phases[y] > 2 * Math.PI) {
                        phases[y] -= 2 * Math.PI;
                    }
                }

                // Нормализация (чтобы не было перегруза/клиппинга)
                // Делим на sqrt(height) или фиксированное число, так как мы сложили много синусоид
                channelData[i] = sampleValue / Math.sqrt(height * 2); 
            }

            // 3. Создание WAV файла для скачивания/воспроизведения
            const wavBlob = bufferToWave(audioBuffer, totalSamples);
            const audioUrl = URL.createObjectURL(wavBlob);
            
            audioPlayer.src = audioUrl;
            statusDiv.innerText = "Готово! Нажмите Play ниже.";
            generateBtn.disabled = false;

        } catch (e) {
            console.error(e);
            statusDiv.innerText = "Ошибка при генерации: " + e.message;
            generateBtn.disabled = false;
        }
    }

    // Вспомогательная функция для конвертации AudioBuffer в WAV Blob
    function bufferToWave(abuffer, len) {
        let numOfChan = abuffer.numberOfChannels,
            length = len * numOfChan * 2 + 44,
            buffer = new ArrayBuffer(length),
            view = new DataView(buffer),
            channels = [], i, sample,
            offset = 0,
            pos = 0;

        // write WAVE header
        setUint32(0x46464952);                         // "RIFF"
        setUint32(length - 8);                         // file length - 8
        setUint32(0x45564157);                         // "WAVE"

        setUint32(0x20746d66);                         // "fmt " chunk
        setUint32(16);                                 // length = 16
        setUint16(1);                                  // PCM (uncompressed)
        setUint16(numOfChan);
        setUint32(abuffer.sampleRate);
        setUint32(abuffer.sampleRate * 2 * numOfChan); // avg. bytes/sec
        setUint16(numOfChan * 2);                      // block-align
        setUint16(16);                                 // 16-bit (hardcoded in this loop)

        setUint32(0x61746164);                         // "data" - chunk
        setUint32(length - pos - 4);                   // chunk length

        // write interleaved data
        for(i = 0; i < abuffer.numberOfChannels; i++)
            channels.push(abuffer.getChannelData(i));

        while(pos < len) {
            for(i = 0; i < numOfChan; i++) {             // interleave channels
                sample = Math.max(-1, Math.min(1, channels[i][pos])); // clamp
                sample = (0.5 + sample < 0 ? sample * 32768 : sample * 32767)|0; // scale to 16-bit signed int
                view.setInt16(44 + offset, sample, true); // write 16-bit sample
                offset += 2;
            }
            pos++;
        }

        return new Blob([buffer], {type: "audio/wav"});

        function setUint16(data) {
            view.setUint16(pos, data, true);
            pos += 2;
        }

        function setUint32(data) {
            view.setUint32(pos, data, true);
            pos += 4;
        }
    }
</script>

</body>
</html>